{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58391fd8-c34c-4459-8108-4c70472f4535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import json\n",
    "\n",
    "class LoadDocument():\n",
    "    def __init__(self) -> None:\n",
    "        self.loader = WebBaseLoader(\"https://kb.zmanda.com/\")\n",
    "        self.set_data = self.loader.load()\n",
    "        #print(self.set_data)\n",
    "\n",
    "    def load_json_file(self,file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "        with open(self.file_path, 'r',encoding='utf-8') as f:\n",
    "            self.docs = json.load(f)\n",
    "        zc_docs = []\n",
    "        zp_docs = []\n",
    "        for doc in self.docs:\n",
    "            if doc['metadata']['tag']['product'] == \"Zmanda-Classic\":\n",
    "                self.set_data[0].metadata['source'] = doc['source']\n",
    "                self.set_data[0].metadata['title'] = doc['title']\n",
    "                if \".pdf\" not in doc['source']:\n",
    "                    self.set_data[0].metadata['language'] = doc['metadata']['language']\n",
    "                    self.set_data[0].metadata['description'] = doc['metadata']['description']\n",
    "                else:\n",
    "                    self.set_data[0].metadata['language'] = \"en\"\n",
    "                    self.set_data[0].metadata['description'] = \"No description found\"\n",
    "                self.set_data[0].page_content = doc['content']\n",
    "                zc_docs.extend(self.set_data)\n",
    "            else:\n",
    "                self.set_data[0].metadata['source'] = doc['source']\n",
    "                self.set_data[0].metadata['title'] = doc['title']\n",
    "                if \".pdf\" not in doc['source']:\n",
    "                    self.set_data[0].metadata['language'] = doc['metadata']['language']\n",
    "                    self.set_data[0].metadata['description'] = doc['metadata']['description']\n",
    "                else:\n",
    "                    self.set_data[0].metadata['language'] = \"en\"\n",
    "                    self.set_data[0].metadata['description'] = \"No description found\"\n",
    "                self.set_data[0].page_content = doc['content']\n",
    "                zp_docs.extend(self.set_data)\n",
    "\n",
    "        \n",
    "        return zc_docs,zp_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c900cd1-2689-4de2-8d48-c98166d4aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import LoadDocument\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "load_dotenv()\n",
    "\n",
    "# Get the Gemini API key\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73ca2c3-de07-42f0-b0a6-cab139a6c00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed document 1\n",
      "Processed document 2\n"
     ]
    }
   ],
   "source": [
    "document1 = LoadDocument()\n",
    "document2 = LoadDocument()\n",
    "\n",
    "data1,data2 = document1.load_json_file(\"output_docs_zmanda_2024-09-23_03-15-39.json\")\n",
    "print(\"Processed document 1\")\n",
    "data3,data4 = document2.load_json_file(\"output_kb_zmanda_2024-08-27_11-35-49.json\")\n",
    "print(\"Processed document 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0299de12-4f61-4505-b6f5-a299d2b5072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zc_docs = data1+data3\n",
    "zp_docs = data2+data4\n",
    "del data1,data2,data3,data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3053b91f-c550-4eeb-95b5-6eb426cdf4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
    "zc_splits = text_splitter.split_documents(zc_docs)\n",
    "zp_splits = text_splitter.split_documents(zp_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558fc71e-b4df-4cce-89f2-dc54457c79ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "zc_vectorstore = Chroma.from_documents(documents=zc_splits, embedding=embeddings)\n",
    "zc_retriever = zc_vectorstore.as_retriever(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1f3168-5da5-47c5-903c-8d04bc98340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zp_vectorstore = Chroma.from_documents(documents=zp_splits, embedding=embeddings)\n",
    "# k is the number of chunks to retrieve\n",
    "zp_retriever = zp_vectorstore.as_retriever(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb29f1a2-6bae-4be0-8c94-817dd73fb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import MergerRetriever\n",
    "lotr = MergerRetriever(retrievers=[zc_retriever, zp_retriever])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95e8fac-2dab-42d6-860d-08ffae31659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\AppData\\Local\\Temp\\ipykernel_19064\\1115570466.py:36: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
      "C:\\Users\\rashm\\AppData\\Local\\Temp\\ipykernel_19064\\1115570466.py:37: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llmchain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "system = \"\"\"\n",
    "Your Name: Zam\n",
    "\n",
    "Your Role: A highly efficient and user-friendly chatbot. Your primary role is to assist users by answering their queries related to two applications: **Zmanda Pro** and **Zmanda Classic**. Always provide clear, detailed, and step-by-step instructions to address user concerns or guide them through processes.\n",
    "\n",
    "Your Knowledge Base: I have access to extensive documentation and resources on both Zmanda Pro and Zmanda Classic. I can guide you through step-by-step instructions for common tasks, troubleshoot issues, and point you in the right direction for more complex problems.\n",
    "\n",
    "Guidelines:  \n",
    "1. Identify which application the query pertains to — Zmanda Pro or Zmanda Classic. If unclear, consider zmanda pro.  \n",
    "2. Focus on providing precise and actionable steps tailored to the user's requirements.\n",
    "3. Prioritize providing clear step-by-step instructions when possible.44\n",
    "4. Use simple, easy-to-understand language, avoiding unnecessary technical jargon unless the user explicitly requests advanced details.  \n",
    "5. If the query is outside the scope of Zmanda Pro or Zmanda Classic, inform the user courteously and suggest possible next steps or resources.  \n",
    "6. Maintain a professional yet approachable tone to\n",
    "7. Offer additional resources if needed.\n",
    "\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm=ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llmchain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d6c8e46-f71f-4a9d-a206-f75ed4aeac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Are you single', 'chat_history': \"Human: Are you single\\nAI: My purpose is to help you with Zmanda Pro and Zmanda Classic.  I'm not designed for personal conversations or questions like that.  Is there anything related to Zmanda I can assist you with?\\n\\nHuman: who are you\\nAI: I am Zam, a chatbot designed to help you with your Zmanda Pro and Zmanda Classic queries. I can provide step-by-step instructions, troubleshoot issues, and guide you through various processes related to these applications.  Do you have any questions about Zmanda that I can answer today?\\n\", 'text': \"My purpose is to help you with Zmanda Pro and Zmanda Classic. I'm not designed for personal conversations. Do you have any Zmanda-related questions I can assist you with?\\n\"}\n"
     ]
    }
   ],
   "source": [
    "print(llmchain.invoke(\"Are you single\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed4e8b61-b393-4939-81b3-7e4ae63dd2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'who are you', 'chat_history': \"Human: Are you single\\nAI: My purpose is to help you with Zmanda Pro and Zmanda Classic.  I'm not designed for personal conversations or questions like that.  Is there anything related to Zmanda I can assist you with?\\n\\nHuman: who are you\\nAI: I am Zam, a chatbot designed to help you with your Zmanda Pro and Zmanda Classic queries. I can provide step-by-step instructions, troubleshoot issues, and guide you through various processes related to these applications.  Do you have any questions about Zmanda that I can answer today?\\n\\nHuman: Are you single\\nAI: My purpose is to help you with Zmanda Pro and Zmanda Classic. I'm not designed for personal conversations. Do you have any Zmanda-related questions I can assist you with?\\n\", 'text': 'I am Zam, a chatbot designed to help you with your Zmanda Pro and Zmanda Classic queries. I can provide step-by-step instructions, troubleshoot issues, and guide you through various processes related to these applications.  Do you have any questions about Zmanda that I can answer today?\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(llmchain.invoke(\"who are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b0a4d60-6d8b-408e-a24b-dc63ce3a7647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Are you single', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"My purpose is to help you with Zmanda Pro and Zmanda Classic.  I'm not designed for personal conversations or questions like that.  Is there anything related to Zmanda I can assist you with?\\n\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am Zam, a chatbot designed to help you with your Zmanda Pro and Zmanda Classic queries. I can provide step-by-step instructions, troubleshoot issues, and guide you through various processes related to these applications.  Do you have any questions about Zmanda that I can answer today?\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Are you single', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"My purpose is to help you with Zmanda Pro and Zmanda Classic. I'm not designed for personal conversations. Do you have any Zmanda-related questions I can assist you with?\\n\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am Zam, a chatbot designed to help you with your Zmanda Pro and Zmanda Classic queries. I can provide step-by-step instructions, troubleshoot issues, and guide you through various processes related to these applications.  Do you have any questions about Zmanda that I can answer today?\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4cdb4eb-a907-450c-ba7f-a7f93d2d1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from langchain.schema import HumanMessage\n",
    "@chain\n",
    "def custom_retriver(prompt: str) -> str:\n",
    "    query = \"\"\n",
    "    for message in memory.chat_memory.messages:\n",
    "        if isinstance(message, HumanMessage):  # Adjust to the correct class\n",
    "            query += \" \" + message.content\n",
    "    query += \" \" + prompt\n",
    "    #print(query)\n",
    "    if \"classic\" in query.lower() and \"pro\" not in query.lower():\n",
    "        print(\"classic\")\n",
    "        return zc_retriever.invoke(query)\n",
    "    elif \"pro\" in query.lower() and \"classic\" not in query.lower():\n",
    "        print(\"pro\")\n",
    "        return zp_retriever.invoke(query)\n",
    "    else:\n",
    "        return lotr.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51366301-e46e-416b-8c29-0445a10acd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Are you single who are you Are you single who are you what is zmanda--- classic\n",
      "classic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'No description found', 'language': 'en', 'source': 'https://www.zmanda.com/wp-content/uploads/2020/03/spectra_and_zmanda_solution_brief.pdf', 'title': 'spectra_and_zmanda_solution_brief.pdf'}, page_content='growth. Zmanda and Spectra combine fast installation, simplified management, enterprise-class functionality and cost-\\neffective storage to deliver a fully integrated solution for data protection. Spectra Logic disk and tape products provide a \\nscalable, cost-effective data management platform to address considerable storage and performance requirements.\\nSpectra Logic Disk and Tape Storage\\nSpectra disk and tape products are designed from the \\nground up to be used as reliable backup and archive \\nstorage targets, providing ease of use, scalability and \\ncost effectiveness. The Spectra Verde® and BlackPearl® \\nNAS Solution’s flexibility delivers capacity, protection \\nand performance options, while tape offers the most \\ncost-effective, long-term storage solution. Compatibility \\nbetween Spectra solutions and Zmanda enables \\nresources to be shared between: \\nEnterprise-Class Storage Solutions\\n•\\t Cost: tape as low as 4 cents/GB (online) and \\n\\t\\n1 cent/GB (offline); disk as low as 7.5 cents/GB'),\n",
       " Document(metadata={'description': 'No description found', 'language': 'en', 'source': 'https://www.zmanda.com/wp-content/uploads/2020/03/spectra_and_zmanda_solution_brief.pdf', 'title': 'spectra_and_zmanda_solution_brief.pdf'}, page_content='growth. Zmanda and Spectra combine fast installation, simplified management, enterprise-class functionality and cost-\\neffective storage to deliver a fully integrated solution for data protection. Spectra Logic disk and tape products provide a \\nscalable, cost-effective data management platform to address considerable storage and performance requirements.\\nSpectra Logic Disk and Tape Storage\\nSpectra disk and tape products are designed from the \\nground up to be used as reliable backup and archive \\nstorage targets, providing ease of use, scalability and \\ncost effectiveness. The Spectra Verde® and BlackPearl® \\nNAS Solution’s flexibility delivers capacity, protection \\nand performance options, while tape offers the most \\ncost-effective, long-term storage solution. Compatibility \\nbetween Spectra solutions and Zmanda enables \\nresources to be shared between: \\nEnterprise-Class Storage Solutions\\n•\\t Cost: tape as low as 4 cents/GB (online) and \\n\\t\\n1 cent/GB (offline); disk as low as 7.5 cents/GB'),\n",
       " Document(metadata={'description': 'No description found', 'language': 'en', 'source': 'https://www.zmanda.com/wp-content/uploads/2020/03/spectra_and_zmanda_solution_brief.pdf', 'title': 'spectra_and_zmanda_solution_brief.pdf'}, page_content='growth. Zmanda and Spectra combine fast installation, simplified management, enterprise-class functionality and cost-\\neffective storage to deliver a fully integrated solution for data protection. Spectra Logic disk and tape products provide a \\nscalable, cost-effective data management platform to address considerable storage and performance requirements.\\nSpectra Logic Disk and Tape Storage\\nSpectra disk and tape products are designed from the \\nground up to be used as reliable backup and archive \\nstorage targets, providing ease of use, scalability and \\ncost effectiveness. The Spectra Verde® and BlackPearl® \\nNAS Solution’s flexibility delivers capacity, protection \\nand performance options, while tape offers the most \\ncost-effective, long-term storage solution. Compatibility \\nbetween Spectra solutions and Zmanda enables \\nresources to be shared between: \\nEnterprise-Class Storage Solutions\\n•\\t Cost: tape as low as 4 cents/GB (online) and \\n\\t\\n1 cent/GB (offline); disk as low as 7.5 cents/GB'),\n",
       " Document(metadata={'description': 'No description found', 'language': 'en', 'source': 'https://www.zmanda.com/wp-content/uploads/2020/03/spectra_and_zmanda_solution_brief.pdf', 'title': 'spectra_and_zmanda_solution_brief.pdf'}, page_content='growth. Zmanda and Spectra combine fast installation, simplified management, enterprise-class functionality and cost-\\neffective storage to deliver a fully integrated solution for data protection. Spectra Logic disk and tape products provide a \\nscalable, cost-effective data management platform to address considerable storage and performance requirements.\\nSpectra Logic Disk and Tape Storage\\nSpectra disk and tape products are designed from the \\nground up to be used as reliable backup and archive \\nstorage targets, providing ease of use, scalability and \\ncost effectiveness. The Spectra Verde® and BlackPearl® \\nNAS Solution’s flexibility delivers capacity, protection \\nand performance options, while tape offers the most \\ncost-effective, long-term storage solution. Compatibility \\nbetween Spectra solutions and Zmanda enables \\nresources to be shared between: \\nEnterprise-Class Storage Solutions\\n•\\t Cost: tape as low as 4 cents/GB (online) and \\n\\t\\n1 cent/GB (offline); disk as low as 7.5 cents/GB')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_retriver.invoke('what is zmanda--- classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcb92711-f673-40f4-9d27-96f777622da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def rag_response(query: str):\n",
    "    documents = custom_retriver.invoke(query)\n",
    "    #print(documents[0].metadata)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    sources = [doc.metadata for doc in documents]\n",
    "    sources = [source['source'] for source in sources]\n",
    "    prompt = f\"\"\"\n",
    "                 Context:\n",
    "                 {context}\n",
    "    \n",
    "                 Question:\n",
    "                 {query}\n",
    "    \n",
    "                 Answer: Provide a direct answer to the query.\n",
    "               \"\"\"\n",
    "    # Generate response using the language model\n",
    "    response = llmchain.invoke(prompt)\n",
    "    return response,str(set(sources))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1151ca-c7fb-491e-8861-65e59d89eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response,sources = rag_response.invoke(\"Where are the Backup Server Files Located?\")\n",
    "print(response['text'])\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52395d60-b1bf-4bb5-901e-9c58b929ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3663dd5f-700a-4466-a0c3-01e6f9ca2c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot: Hi! i am Zam,what can i help you with today\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "memory.clear()\n",
    "print(\"ChatBot: Hi! i am Zam,what can i help you with today\")\n",
    "while True:\n",
    "    query=input(\"You: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    result , source = rag_response.invoke(query)\n",
    "    print(\"chatbot\",result['text'],\"\\n\",source)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9019c48d-ecec-460a-bfeb-d2f1c439e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(query,chat_history):\n",
    "  result , source = rag_response.invoke(query)\n",
    "  result['text'] = result['text'] + \"\\n\"+\"Here are the links that you refer\\n\"+source\n",
    "  chat_history.extend([(query,result['text'])])\n",
    "  return \"\",chat_history\n",
    "\n",
    "def clear_function():\n",
    "    memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e9032-4d3f-4f23-ad56-37642b85334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\components\\chatbot.py:237: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How do i back up VMware workload\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=540) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "   # with gr.Accordion(label=\"Advanced options\",open=False):\n",
    "   #    system = gr.Textbox(label=\"System message\", lines=2, value=\"A conversation between a user and an LLM-based AI assistant. The assistant gives helpful and honest answers.\")\n",
    "   #     temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(response, inputs=[msg,chatbot], outputs=[msg, chatbot])\n",
    "    clear.click(fn=clear_function)\n",
    "    msg.submit(response, inputs=[msg,chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "\n",
    "gr.close_all()\n",
    "demo.queue().launch(share=True,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a32deeb9-c41b-45e7-bada-690bc0646344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Are you single', 'chat_history': '', 'text': \"My purpose is to help you with Zmanda Pro and Zmanda Classic.  I don't have a personal life or relationship status.  How can I assist you with these applications today?\\n\"}\n"
     ]
    }
   ],
   "source": [
    "print(llmchain.invoke(\"Are you single\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366e236-63a4-4523-b5ba-36d55109e962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
